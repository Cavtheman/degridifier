\subsection{Real data}
Because of the increasing use of online tools for playing D\&D, there is also a large amount of people making these battlemaps and posting them on the internet for others to use. Thus, the data for this project consists solely of images that have been scraped off various forums and sites on the internet.\footnote{https://www.kassoon.com/dnd/battle-maps/}\footnote{https://dnd.wizards.com/articles/features/schley-stack}\footnote{http://archive.wizards.com/default.asp?x=dnd/mwa/archiveall}\footnote{https://www.reddit.com/r/battlemaps/} The data is split into two categories, those with grids and those without, as a cycleGAN requires examples of both to convert between them. Overall, I have gathered $613$ images without grids and $810$ with. These have been split 80/10/10 into training, validation and test sets respectively. All results reported in this report are from the test set, which has not been used before. In addition, during training, all images are randomly cropped to $400$x$400$ size. Since convolutional networks are spatially invariant, this should not cause any problems with learning.

Whilst it is easy to find both examples of images with and without these grids, it is difficult to find images where both versions are available, which severely limits the opportunity for supervised learning. Even if one was to find examples where both versions are available, these examples would be heavily biased towards images I would consider higher quality, and often have similar ``styles'' of grids, distinct from many other sources, since they come primarily from a small subset of these. A model trained on this data is likely to have trouble generalizing to data from other sources. This is the reason for using the cycleGAN. Additionally, there is a significant variance in size and resolution of the data, and thus the grids, which potentially causes problems since CNNs are not size invariant.

The data scraped off the internet was obviously not labelled and sorted into the neat categories (which I will call ``grid'' and ``nogrid'' from now on) by default, so this had to be done manually. The data itself is not actually as clearly separated as it may sound, however. While some of these images may have a grid entirely overlaid, some only have grids in buildings, and sometimes the grids are hidden by trees, roofs, etc. Other times, the grid takes the shape of square flagstones or tiles in a floor, as part of the aesthetic of the image. Since it should not pose a U-net model too much trouble to \textit{not} change an image in certain places, I have decided to categorize all images only partially covered in grids as gridded. The images with the grid as part of the aesthetic have also been categorized as gridded, though this decision is definitely debatable, both because it is likely significantly more difficult for a model to see, and because it removes something that may be important for humans to understand the image. Examples of this can be seen in Figure \ref{image:example}
\begin{figure}[H]
  \centering
  \captionsetup{justification=centering}
  \includegraphics[width=0.30\linewidth]{images/tiles.png}
  \includegraphics[width=0.35\linewidth]{images/overlaid.png}
  \includegraphics[width=0.28\linewidth]{images/partial.png}
  \caption[center]{Cutouts of different ``styles'' of grids. Left: An image with flagstones as a grid. \\Middle: A grid overlaid the entire image. Right: Only ``traversible'' terrain is gridded.}\label{image:example}
\end{figure}

\subsection{Artificial data}
Due to the relative difficulty of finding these real and varied grids, and due to the difficulty of finding paired images of both categories, I started off by training the models on artificial data. This artificial data is created by taking images in the nogrid category as labels, and adding random grids onto these programatically. These artificial grids are generated randomly offset, 1 pixel thick, with random intensity between $-1$ and $1$ (added onto the pixel values) with 30-90 pixel sides. These values were picked to get as much variety in grids as possible easily.

This artificial dataset will be significantly easier to train models on, since the structure of the grid is the exact same between all images. Compared to the real data, where some lines may be dotted, irregular, crooked, discontinuous, etc. Because of this, the models will be trained on this data first. It also allows for supervised learning, since we then have paired examples of images with and without grids.
