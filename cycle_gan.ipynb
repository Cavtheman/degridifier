{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# My own files\n",
    "from data_generator import CombinedDataset, ArtificialDataset\n",
    "from discriminator import *\n",
    "from resunet import ResUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() and True\n",
    "print(\"Using GPU:\", use_cuda)\n",
    "processor = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "#torch.backends.cudnn.deterministic=True\n",
    "\n",
    "\n",
    "# Initialising the data generator and model\n",
    "grid_path = \"data/train/grid/\"\n",
    "nogrid_path = \"data/train/nogrid/\"\n",
    "\n",
    "batch_size = 1\n",
    "max_imgs = 5000\n",
    "\n",
    "augments = {\"crop\" : (400,400),\n",
    "            \"hflip\" : 0.5,\n",
    "            \"vflip\" : 0.5,\n",
    "            \"angle\" : 0,\n",
    "            \"shear\" : 0,\n",
    "            \"brightness\" : (0.75,1.25),\n",
    "            \"pad\" : (0,0,0,0),\n",
    "            \"contrast\" : (0.5,2.0)}\n",
    "\n",
    "artificial_augments = {\"grid_size\" : (30,90),\n",
    "                       \"grid_intensity\" : (-1,1),\n",
    "                       \"grid_offset_x\" : (0,90),\n",
    "                       \"grid_offset_y\" : (0,90),\n",
    "                       \"crop\" : (400,400),\n",
    "                       \"hflip\" : 0.5,\n",
    "                       \"vflip\" : 0.5,\n",
    "                       \"angle\" : 0,\n",
    "                       \"shear\" : 0,\n",
    "                       \"brightness\" : (0.75,1.25),\n",
    "                       \"pad\" : (0,0,0,0),\n",
    "                       \"contrast\" : (0.5,2.0)}\n",
    "\n",
    "#dataset = CombinedDataset(max_imgs, grid_path, nogrid_path, **augments)\n",
    "#validation_set = CombinedDataset(max_imgs, grid_path, nogrid_path, **augments, seed=1337)\n",
    "dataset = ArtificialDataset(max_imgs, nogrid_path, **artificial_augments)\n",
    "validation_set = ArtificialDataset(max_imgs, nogrid_path, **artificial_augments, seed=1337)\n",
    "\n",
    "training_generator = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "validation_generator = data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "#loaded_params = torch.load(\"lstm_1_layer_with_schedule_1024_minloss.pth\")\n",
    "#model = LSTM_model(**loaded_params[\"args_dict\"]).to(processor)\n",
    "#model.load_state_dict(loaded_params[\"state_dict\"])\n",
    "\n",
    "nogrid_disc = Discriminator (3).to(processor)\n",
    "grid_disc = Discriminator (3).to(processor)\n",
    "\n",
    "loaded_params = torch.load(\"saved/resunet/clamp_final_l2.pth\")\n",
    "nogrid_gen = ResUnet (**loaded_params[\"args_dict\"]).to(processor)\n",
    "nogrid_gen.load_state_dict(loaded_params[\"state_dict\"])\n",
    "#nogrid_gen = ResUnet (3, 3).to(processor)\n",
    "\n",
    "grid_gen = ResUnet (**loaded_params[\"args_dict\"]).to(processor)\n",
    "grid_gen.load_state_dict(loaded_params[\"state_dict\"])\n",
    "grid_gen = ResUnet (3, 3).to(processor)\n",
    "\n",
    "cycle_loss = nn.L1Loss().to(processor)\n",
    "id_loss = nn.L1Loss().to(processor)\n",
    "#adv_loss = nn.MSELoss().to(processor)\n",
    "adv_loss = nn.BCELoss().to(processor)\n",
    "#adv_loss = nn.BCEWithLogitsLoss().to(processor)\n",
    "\n",
    "\n",
    "gen_opt = optim.Adam (chain (nogrid_gen.parameters(), grid_gen.parameters()), lr=1e-4)\n",
    "#grid_gen_opt = optim.Adam (grid_gen.parameters(), lr=1e-4)\n",
    "#nogrid_gen_opt = optim.Adam (nogrid_gen.parameters(), lr =1e-4)\n",
    "nogrid_disc_opt = optim.Adam (nogrid_disc.parameters(), lr=1e-4)\n",
    "grid_disc_opt = optim.Adam (grid_disc.parameters(), lr=1e-4)\n",
    "                              \n",
    "#scheduler = optim.lr_scheduler.StepLR (optimiser, step_size=10, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialising some variables for use in training\n",
    "batches = float(\"inf\")\n",
    "time_diff = 0\n",
    "no_improv = 0\n",
    "min_loss = float(\"inf\")\n",
    "val_loss = float(\"inf\")\n",
    "min_val_loss = float(\"inf\")\n",
    "epochs = 5\n",
    "early_stop_epoch = 0\n",
    "\n",
    "grid_gen_losses = []\n",
    "nogrid_gen_losses = []\n",
    "\n",
    "real_grid_disc_losses = []\n",
    "real_nogrid_disc_losses = []\n",
    "\n",
    "fake_grid_disc_losses = []\n",
    "fake_nogrid_disc_losses = []\n",
    "\n",
    "grid_disc_losses = []\n",
    "nogrid_disc_losses = []\n",
    "\n",
    "val_grid_gen_losses = []\n",
    "val_nogrid_gen_losses = []\n",
    "\n",
    "val_real_grid_disc_losses = []\n",
    "val_real_nogrid_disc_losses = []\n",
    "\n",
    "val_fake_grid_disc_losses = []\n",
    "val_fake_nogrid_disc_losses = []\n",
    "\n",
    "val_grid_disc_losses = []\n",
    "val_nogrid_disc_losses = []\n",
    "\n",
    "id_losses = []\n",
    "gan_losses = []\n",
    "cycle_losses = []\n",
    "\n",
    "gen_losses = []\n",
    "val_gen_losses = []\n",
    "\n",
    "id_loss_mult = 5\n",
    "gan_loss_mult = 5\n",
    "cycle_loss_mult = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in enumerate(training_generator):\n",
    "\n",
    "        # Keeping track of stuff\n",
    "        start_time = datetime.now()\n",
    "        est_time_left = str(time_diff*(min(batches, dataset.__len__()) - i)+time_diff*(epochs-(epoch+1))*min(batches, dataset.__len__()/batch_size)).split(\".\")[0]\n",
    "        \n",
    "        sys.stdout.write(\"\\rEpoch: {0}. Batch: {1}. Min loss: {2:.5f}. Time left: {3}. Best: {4} batches ago. Val loss: {5:.5f}\".format(epoch+1, i+1, min_loss, est_time_left, no_improv, val_loss))\n",
    "\n",
    "        # Putting data on gpu\n",
    "        real_grid = batch[\"grid\"].to(processor)\n",
    "        real_nogrid = batch[\"nogrid\"].to(processor)\n",
    "\n",
    "        real_label = torch.full((batch_size, 1), 1, device=processor, dtype=torch.float32)\n",
    "        fake_label = torch.full((batch_size, 1), 0, device=processor, dtype=torch.float32)\n",
    "        \n",
    "        nogrid_disc.train()\n",
    "        nogrid_gen.train()\n",
    "        grid_disc.train()\n",
    "        grid_gen.train()\n",
    "\n",
    "                \n",
    "        gen_opt.zero_grad()\n",
    "        #grid_gen_opt.zero_grad()\n",
    "        #nogrid_gen_opt.zero_grad()\n",
    "\n",
    "        # Training the generators\n",
    "\n",
    "        # Identity loss\n",
    "        id_grid = grid_gen (real_grid)\n",
    "        id_grid_loss = id_loss (id_grid, real_grid) * id_loss_mult\n",
    "\n",
    "        id_nogrid = grid_gen (real_nogrid)\n",
    "        id_nogrid_loss = id_loss (id_nogrid, real_nogrid) * id_loss_mult\n",
    "\n",
    "        \n",
    "        # GAN loss\n",
    "        fake_grid = grid_gen (real_nogrid)\n",
    "        fake_grid_pred = grid_disc (fake_grid)\n",
    "        gan_loss_grid = adv_loss (fake_grid_pred, real_label) * gan_loss_mult\n",
    "        \n",
    "        fake_nogrid = nogrid_gen(real_grid)\n",
    "        fake_nogrid_pred = nogrid_disc (fake_nogrid)\n",
    "        gan_loss_nogrid = adv_loss (fake_nogrid_pred, real_label) * gan_loss_mult\n",
    "\n",
    "        \n",
    "        # Cycle loss\n",
    "        cycled_grid = grid_gen (fake_nogrid)\n",
    "        cycle_loss_grid = cycle_loss (cycled_grid, real_grid) * cycle_loss_mult\n",
    "\n",
    "        cycled_nogrid = nogrid_gen (fake_grid)\n",
    "        cycle_loss_nogrid = cycle_loss (cycled_nogrid, real_nogrid) * cycle_loss_mult\n",
    "        \n",
    "        gen_loss = id_grid_loss + id_nogrid_loss + gan_loss_grid + gan_loss_nogrid + cycle_loss_grid + cycle_loss_nogrid\n",
    "        #gen_loss = id_nogrid_loss + gan_loss_nogrid + cycle_loss_nogrid\n",
    "        #grid_gen_loss = id_grid_loss + gan_loss_grid + cycle_loss_grid\n",
    "\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        #grid_gen_opt.step()\n",
    "        \n",
    "        #grid_gen_loss.backward()\n",
    "        #nogrid_gen_opt.step()\n",
    "\n",
    "        # Training the discriminators\n",
    "\n",
    "        # Grid discriminator\n",
    "        grid_disc_opt.zero_grad()\n",
    "\n",
    "        real_grid_disc = grid_disc (real_grid)\n",
    "        real_grid_disc_loss = adv_loss (real_grid_disc, real_label)\n",
    "\n",
    "        fake_grid_disc = grid_disc (fake_grid.detach())\n",
    "        fake_grid_disc_loss = adv_loss (fake_grid_disc, fake_label)\n",
    "\n",
    "        grid_disc_loss = (real_grid_disc_loss + fake_grid_disc_loss)/2 # Is /2 necessary?\n",
    "        \n",
    "        grid_disc_loss.backward()\n",
    "        grid_disc_opt.step()\n",
    "        \n",
    "\n",
    "        # Nogrid discriminator\n",
    "        grid_disc_opt.zero_grad()\n",
    "\n",
    "        real_nogrid_disc = nogrid_disc (real_nogrid)\n",
    "        real_nogrid_disc_loss = adv_loss (real_nogrid_disc, real_label)\n",
    "\n",
    "        fake_nogrid_disc = nogrid_disc (fake_nogrid.detach())\n",
    "        fake_nogrid_disc_loss = adv_loss (fake_nogrid_disc, fake_label)\n",
    "\n",
    "        nogrid_disc_loss = (real_nogrid_disc_loss + fake_nogrid_disc_loss)/2 # Is /2 necessary?\n",
    "\n",
    "        nogrid_disc_loss.backward()\n",
    "        nogrid_disc_opt.step()\n",
    "\n",
    "        grid_gen_losses.append((id_grid_loss+gan_loss_grid+cycle_loss_grid).item())\n",
    "        nogrid_gen_losses.append((id_nogrid_loss+gan_loss_nogrid+cycle_loss_nogrid).item())\n",
    "        \n",
    "        real_grid_disc_losses.append(real_grid_disc_loss.item())\n",
    "        real_nogrid_disc_losses.append(real_nogrid_disc_loss.item())\n",
    "        \n",
    "        nogrid_disc_losses.append(nogrid_disc_loss.item())\n",
    "        grid_disc_losses.append(grid_disc_loss.item())\n",
    "\n",
    "        fake_grid_disc_losses.append(fake_grid_disc_loss.item())\n",
    "        fake_nogrid_disc_losses.append(fake_nogrid_disc_loss.item())\n",
    "\n",
    "        id_losses.append((id_grid_loss + id_nogrid_loss).item())\n",
    "        gan_losses.append((gan_loss_grid + gan_loss_nogrid).item())\n",
    "        cycle_losses.append((cycle_loss_grid + cycle_loss_nogrid).item())\n",
    "        gen_losses.append(gen_loss.item())\n",
    "        \n",
    "        if i < 1:\n",
    "            if real_grid.size()[0] == 1:\n",
    "                #to_save = out\n",
    "                to_save = torch.cat ((real_grid, fake_nogrid, real_nogrid, fake_grid), dim=2)\n",
    "                #to_save = torch.cat ((labels, out), dim=2)\n",
    "            else:\n",
    "                #to_save = out.squeeze(0)\n",
    "                to_save = torch.cat ((real_grid, fake_nogrid.squeeze(0), real_nogrid, fake_grid.squeeze(0)), dim=2)\n",
    "                #to_save = torch.cat ((labels, out.squeeze(0), batch), dim=2)\n",
    "                #to_save = torch.cat ((labels, out.squeeze(0)), dim=2)\n",
    "                #print(to_save.size())\n",
    "            save_image(to_save, \"data/training_temp/test.png\")\n",
    "            \n",
    "        if gen_loss.item() < min_loss:\n",
    "            #model.save(\"temp_best_model.pth\")\n",
    "            #torch.save(model.state_dict(), \"temp_best_model.pth\")\n",
    "            min_loss = gen_loss.item()\n",
    "            no_improv = 0\n",
    "        else:\n",
    "            no_improv += 1\n",
    "    \n",
    "        # For tracking progress\n",
    "        end_time = datetime.now()\n",
    "        time_diff = end_time - start_time\n",
    "\n",
    "    val_gen_loss = 0\n",
    "    val_grid_gen_loss = 0\n",
    "    val_nogrid_gen_loss = 0\n",
    "    \n",
    "    val_real_grid_disc_loss = 0\n",
    "    val_real_nogrid_disc_loss = 0\n",
    "    \n",
    "    val_fake_grid_disc_loss = 0\n",
    "    val_fake_nogrid_disc_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        nogrid_disc.eval()\n",
    "        nogrid_gen.eval()\n",
    "        grid_disc.eval()\n",
    "        grid_gen.eval()\n",
    "        for i, batch in enumerate (validation_generator):\n",
    "            # Putting data on gpu\n",
    "            real_grid = batch[\"grid\"].to(processor)\n",
    "            real_nogrid = batch[\"nogrid\"].to(processor)\n",
    "            \n",
    "            real_label = torch.full((batch_size, 1), 1, device=processor, dtype=torch.float32)\n",
    "            fake_label = torch.full((batch_size, 1), 0, device=processor, dtype=torch.float32)\n",
    "            \n",
    "            # Identity loss\n",
    "            id_grid = grid_gen (real_grid)\n",
    "            id_grid_loss = id_loss (id_grid, real_grid)\n",
    "            \n",
    "            id_nogrid = grid_gen (real_nogrid)\n",
    "            id_nogrid_loss = id_loss (id_nogrid, real_nogrid)\n",
    "            \n",
    "            \n",
    "            # GAN loss\n",
    "            fake_grid = grid_gen (real_nogrid)\n",
    "            fake_grid_pred = grid_disc (fake_grid)\n",
    "            gan_loss_grid = adv_loss (fake_grid_pred, real_label)\n",
    "            \n",
    "            fake_nogrid = nogrid_gen(real_grid)\n",
    "            fake_nogrid_pred = nogrid_disc (fake_nogrid)\n",
    "            gan_loss_nogrid = adv_loss (fake_nogrid_pred, real_label)\n",
    "            \n",
    "            \n",
    "            # Cycle loss\n",
    "            cycled_grid = grid_gen (fake_nogrid)\n",
    "            cycle_loss_grid = cycle_loss (cycled_grid, real_grid)\n",
    "            \n",
    "            cycled_nogrid = nogrid_gen (fake_grid)\n",
    "            cycle_loss_nogrid = cycle_loss (cycled_nogrid, real_nogrid)\n",
    "            \n",
    "            gen_loss = id_grid_loss + id_nogrid_loss + gan_loss_grid + gan_loss_nogrid + cycle_loss_grid + cycle_loss_nogrid\n",
    "            \n",
    "            val_grid_gen_loss += (id_grid_loss+gan_loss_grid+cycle_loss_grid).item()\n",
    "            val_nogrid_gen_loss += (id_nogrid_loss+gan_loss_nogrid+cycle_loss_nogrid).item()\n",
    "            \n",
    "            val_real_grid_disc_loss += real_grid_disc_loss.item()\n",
    "            val_real_nogrid_disc_loss += real_nogrid_disc_loss.item()\n",
    "\n",
    "            val_fake_grid_disc_loss += fake_grid_disc_loss.item()\n",
    "            val_fake_nogrid_disc_loss += fake_nogrid_disc_loss.item()\n",
    "            \n",
    "            val_gen_loss += gen_loss.item()\n",
    "\n",
    "            if i < 10:\n",
    "                if real_grid.size()[0] == 1:\n",
    "                    #to_save = out\n",
    "                    to_save = torch.cat ((real_grid, fake_nogrid, real_nogrid, fake_grid), dim=2)\n",
    "                    #to_save = torch.cat ((labels, out), dim=2)\n",
    "                else:\n",
    "                    #to_save = out.squeeze(0)\n",
    "                    to_save = torch.cat ((real_grid, fake_nogrid.squeeze(0), real_nogrid, fake_grid.squeeze(0)), dim=2)\n",
    "                    #to_save = torch.cat ((labels, out.squeeze(0), batch), dim=2)\n",
    "                    #to_save = torch.cat ((labels, out.squeeze(0)), dim=2)\n",
    "                    #print(to_save.size())\n",
    "                save_image(to_save, \"data/training_temp/{}_{}.png\".format(epoch+1, i))\n",
    "        \n",
    "    val_loss = val_loss/len(validation_generator)\n",
    "    val_grid_gen_loss = val_grid_gen_loss/len(validation_generator)\n",
    "    val_nogrid_gen_loss = val_nogrid_gen_loss/len(validation_generator)\n",
    "        \n",
    "    val_real_grid_disc_loss = val_real_grid_disc_loss/len(validation_generator)\n",
    "    val_real_nogrid_disc_loss = val_real_nogrid_disc_loss/len(validation_generator)\n",
    "    \n",
    "    val_fake_grid_disc_loss = val_fake_grid_disc_loss/len(validation_generator)\n",
    "    val_fake_nogrid_disc_loss = val_fake_nogrid_disc_loss/len(validation_generator)\n",
    "    \n",
    "    if val_nogrid_gen_loss < min_val_loss:\n",
    "        min_val_loss = val_nogrid_gen_loss\n",
    "        early_stop_epoch = epoch + 1\n",
    "        grid_gen.save(\"early_stop_grid_gen.pth\")\n",
    "        nogrid_gen.save(\"early_stop_nogrid_gen.pth\")\n",
    "        grid_disc.save(\"early_stop_grid_disc.pth\")\n",
    "        nogrid_disc.save(\"early_stop_nogrid_disc.pth\")\n",
    "        \n",
    "    val_gen_losses.append(val_gen_loss)\n",
    "    val_grid_gen_losses.append(val_grid_gen_loss)\n",
    "    val_nogrid_gen_losses.append(val_nogrid_gen_loss)\n",
    "    \n",
    "    val_real_grid_disc_losses.append(val_real_grid_disc_loss)\n",
    "    val_real_nogrid_disc_losses.append(val_real_nogrid_disc_loss)\n",
    "    \n",
    "    val_fake_grid_disc_losses.append(val_fake_grid_disc_loss)\n",
    "    val_fake_nogrid_disc_losses.append(val_fake_nogrid_disc_loss)\n",
    "\n",
    "grid_gen.save(\"final_grid_gen.pth\")\n",
    "nogrid_gen.save(\"final_nogrid_gen.pth\")\n",
    "grid_disc.save(\"final_grid_disc.pth\")\n",
    "nogrid_disc.save(\"final_nogrid_disc.pth\")\n",
    "print (\"\\nFinished. Early stop was at:\", early_stop_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the loss through the epochs\n",
    "train_placings = np.linspace(0,epoch+1,len(gen_losses))\n",
    "val_placings = np.arange (1, epoch+2)\n",
    "\n",
    "grid_fig, grid_ax = plt.subplots(2, figsize=(16,16))\n",
    "\n",
    "grid_ax[0].plot(train_placings, grid_gen_losses, label=\"Generator\")\n",
    "grid_ax[1].plot(train_placings, real_grid_disc_losses, label=\"Real discriminator\")\n",
    "grid_ax[1].plot(train_placings, grid_disc_losses, label=\"Combined\")\n",
    "grid_ax[1].plot(train_placings, fake_grid_disc_losses, label=\"Fake discriminator\")\n",
    "\n",
    "grid_ax[0].plot(val_placings, val_grid_gen_losses, label=\"Generator (validation)\")\n",
    "grid_ax[1].plot(val_placings, val_real_grid_disc_losses, label=\"Real discriminator (validation)\")\n",
    "grid_ax[1].plot(val_placings, val_fake_grid_disc_losses, label=\"Fake discriminator (validation)\")\n",
    "\n",
    "grid_ax[0].set_title(\"Grid generator loss during training\")\n",
    "grid_ax[1].set_title(\"Grid discriminator loss during training\")\n",
    "grid_ax[0].set_ylabel(\"Loss\")\n",
    "grid_ax[0].set_xlabel(\"Epoch\")\n",
    "grid_ax[1].set_ylabel(\"Loss\")\n",
    "grid_ax[1].set_xlabel(\"Epoch\")\n",
    "#ax[0].yscale(\"log\")\n",
    "\n",
    "grid_ax[0].legend()\n",
    "grid_ax[1].legend()\n",
    "grid_fig.savefig(\"grid_loss_log.png\")\n",
    "grid_fig.show()\n",
    "\n",
    "nogrid_fig, nogrid_ax = plt.subplots(2, figsize=(16,16))\n",
    "\n",
    "nogrid_ax[0].plot(train_placings, nogrid_gen_losses, label=\"Generator\")\n",
    "nogrid_ax[1].plot(train_placings, real_nogrid_disc_losses, label=\"Real discriminator\")\n",
    "nogrid_ax[1].plot(train_placings, nogrid_disc_losses, label=\"Combined\")\n",
    "nogrid_ax[1].plot(train_placings, fake_nogrid_disc_losses, label=\"Fake discriminator\")\n",
    "\n",
    "nogrid_ax[0].plot(val_placings, val_nogrid_gen_losses, label=\"Generator (validation)\")\n",
    "nogrid_ax[1].plot(val_placings, val_real_nogrid_disc_losses, label=\"Real discriminator (validation)\")\n",
    "nogrid_ax[1].plot(val_placings, val_fake_nogrid_disc_losses, label=\"Fake discriminator (validation)\")\n",
    "\n",
    "nogrid_ax[0].set_title(\"Nogrid generator loss during training\")\n",
    "nogrid_ax[1].set_title(\"Nogrid discriminator loss during training\")\n",
    "nogrid_ax[0].set_ylabel(\"Loss\")\n",
    "nogrid_ax[0].set_xlabel(\"Epoch\")\n",
    "nogrid_ax[1].set_ylabel(\"Loss\")\n",
    "nogrid_ax[1].set_xlabel(\"Epoch\")\n",
    "#ax[0].yscale(\"log\")\n",
    "\n",
    "nogrid_ax[0].legend()\n",
    "nogrid_ax[1].legend()\n",
    "nogrid_fig.savefig(\"nogrid_loss_log.png\")\n",
    "nogrid_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "cycle_gan.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
